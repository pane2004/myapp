{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled0.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1jYU5ksjmPi4"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import os"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/dataset.zip"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tja2Hu7fmVv1",
        "outputId": "79c62860-83b5-42a4-be14-1a106307da28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Archive:  /content/dataset.zip\n",
            "   creating: dataset/test/\n",
            "   creating: dataset/test/Compost/\n",
            "  inflating: dataset/test/Compost/O_12787.jpg  \n",
            "  inflating: dataset/test/Compost/O_12788.jpg  \n",
            "  inflating: dataset/test/Compost/O_12789.jpg  \n",
            "  inflating: dataset/test/Compost/O_12790.jpg  \n",
            "  inflating: dataset/test/Compost/O_12791.jpg  \n",
            "  inflating: dataset/test/Compost/O_12792.jpg  \n",
            "  inflating: dataset/test/Compost/O_12793.jpg  \n",
            "  inflating: dataset/test/Compost/O_12794.jpg  \n",
            "  inflating: dataset/test/Compost/O_12795.jpg  \n",
            "  inflating: dataset/test/Compost/O_12796.jpg  \n",
            "  inflating: dataset/test/Compost/O_12797.jpg  \n",
            "  inflating: dataset/test/Compost/O_12798.jpg  \n",
            "  inflating: dataset/test/Compost/O_12799.jpg  \n",
            "  inflating: dataset/test/Compost/O_12800.jpg  \n",
            "  inflating: dataset/test/Compost/O_12801.jpg  \n",
            "  inflating: dataset/test/Compost/O_12802.jpg  \n",
            "  inflating: dataset/test/Compost/O_12803.jpg  \n",
            "  inflating: dataset/test/Compost/O_12804.jpg  \n",
            "  inflating: dataset/test/Compost/O_12805.jpg  \n",
            "  inflating: dataset/test/Compost/O_12806.jpg  \n",
            "  inflating: dataset/test/Compost/O_12807.jpg  \n",
            "  inflating: dataset/test/Compost/O_12808.jpg  \n",
            "  inflating: dataset/test/Compost/O_12809.jpg  \n",
            "  inflating: dataset/test/Compost/O_12810.jpg  \n",
            "  inflating: dataset/test/Compost/O_12811.jpg  \n",
            "  inflating: dataset/test/Compost/O_12812.jpg  \n",
            "  inflating: dataset/test/Compost/O_12813.jpg  \n",
            "  inflating: dataset/test/Compost/O_12814.jpg  \n",
            "  inflating: dataset/test/Compost/O_12815.jpg  \n",
            "   creating: dataset/test/Recycling/\n",
            "  inflating: dataset/test/Recycling/aluminumcans12.jpeg  \n",
            "  inflating: dataset/test/Recycling/aluminumcans13.jpeg  \n",
            "  inflating: dataset/test/Recycling/aluminumcans14.jpeg  \n",
            "  inflating: dataset/test/Recycling/aluminumcans15.jpeg  \n",
            " extracting: dataset/test/Recycling/aluminumcans17.png  \n",
            "  inflating: dataset/test/Recycling/aluminumcans18.jpeg  \n",
            "  inflating: dataset/test/Recycling/aluminumcans19.jpeg  \n",
            "  inflating: dataset/test/Recycling/aluminumfoil10.jpeg  \n",
            "  inflating: dataset/test/Recycling/aluminumfoil12.png  \n",
            "  inflating: dataset/test/Recycling/aluminumfoil13.jpeg  \n",
            "  inflating: dataset/test/Recycling/aluminumfoil14.jpeg  \n",
            "  inflating: dataset/test/Recycling/aluminumfoil15.jpeg  \n",
            "  inflating: dataset/test/Recycling/aluminumfoil16.jpeg  \n",
            "  inflating: dataset/test/Recycling/aluminumfoil17.jpeg  \n",
            "  inflating: dataset/test/Recycling/aluminumfoil8.jpeg  \n",
            "  inflating: dataset/test/Recycling/aluminumfoil9.jpeg  \n",
            "   creating: dataset/train/\n",
            "   creating: dataset/train/Compost/\n",
            "  inflating: dataset/train/Compost/O_12568.jpg  \n",
            "  inflating: dataset/train/Compost/O_12569.jpg  \n",
            "  inflating: dataset/train/Compost/O_12570.jpg  \n",
            "  inflating: dataset/train/Compost/O_12571.jpg  \n",
            "  inflating: dataset/train/Compost/O_12572.jpg  \n",
            "  inflating: dataset/train/Compost/O_12573.jpg  \n",
            "  inflating: dataset/train/Compost/O_12574.jpg  \n",
            "  inflating: dataset/train/Compost/O_12575.jpg  \n",
            "  inflating: dataset/train/Compost/O_12576.jpg  \n",
            "  inflating: dataset/train/Compost/O_12577.jpg  \n",
            "  inflating: dataset/train/Compost/O_12578.jpg  \n",
            "  inflating: dataset/train/Compost/O_12579.jpg  \n",
            "  inflating: dataset/train/Compost/O_12580.jpg  \n",
            "  inflating: dataset/train/Compost/O_12581.jpg  \n",
            "  inflating: dataset/train/Compost/O_12582.jpg  \n",
            "  inflating: dataset/train/Compost/O_12583.jpg  \n",
            "  inflating: dataset/train/Compost/O_12584.jpg  \n",
            "  inflating: dataset/train/Compost/O_12585.jpg  \n",
            "  inflating: dataset/train/Compost/O_12586.jpg  \n",
            "  inflating: dataset/train/Compost/O_12587.jpg  \n",
            "  inflating: dataset/train/Compost/O_12588.jpg  \n",
            "  inflating: dataset/train/Compost/O_12589.jpg  \n",
            "  inflating: dataset/train/Compost/O_12590.jpg  \n",
            "  inflating: dataset/train/Compost/O_12591.jpg  \n",
            "  inflating: dataset/train/Compost/O_12592.jpg  \n",
            "  inflating: dataset/train/Compost/O_12593.jpg  \n",
            "  inflating: dataset/train/Compost/O_12594.jpg  \n",
            "  inflating: dataset/train/Compost/O_12595.jpg  \n",
            "  inflating: dataset/train/Compost/O_12596.jpg  \n",
            "  inflating: dataset/train/Compost/O_12597.jpg  \n",
            "  inflating: dataset/train/Compost/O_12598.jpg  \n",
            "  inflating: dataset/train/Compost/O_12599.jpg  \n",
            "  inflating: dataset/train/Compost/O_12600.jpg  \n",
            "  inflating: dataset/train/Compost/O_12601.jpg  \n",
            "  inflating: dataset/train/Compost/O_12602.jpg  \n",
            "  inflating: dataset/train/Compost/O_12603.jpg  \n",
            "  inflating: dataset/train/Compost/O_12604.jpg  \n",
            "  inflating: dataset/train/Compost/O_12605.jpg  \n",
            "  inflating: dataset/train/Compost/O_12606.jpg  \n",
            "  inflating: dataset/train/Compost/O_12607.jpg  \n",
            "  inflating: dataset/train/Compost/O_12608.jpg  \n",
            "  inflating: dataset/train/Compost/O_12609.jpg  \n",
            "  inflating: dataset/train/Compost/O_12610.jpg  \n",
            "  inflating: dataset/train/Compost/O_12611.jpg  \n",
            "  inflating: dataset/train/Compost/O_12612.jpg  \n",
            "  inflating: dataset/train/Compost/O_12613.jpg  \n",
            "  inflating: dataset/train/Compost/O_12614.jpg  \n",
            "  inflating: dataset/train/Compost/O_12615.jpg  \n",
            "  inflating: dataset/train/Compost/O_12616.jpg  \n",
            "  inflating: dataset/train/Compost/O_12617.jpg  \n",
            "  inflating: dataset/train/Compost/O_12618.jpg  \n",
            "  inflating: dataset/train/Compost/O_12619.jpg  \n",
            "  inflating: dataset/train/Compost/O_12620.jpg  \n",
            "  inflating: dataset/train/Compost/O_12621.jpg  \n",
            "  inflating: dataset/train/Compost/O_12622.jpg  \n",
            "  inflating: dataset/train/Compost/O_12623.jpg  \n",
            "   creating: dataset/train/Recycling/\n",
            "  inflating: dataset/train/Recycling/aluminumcans0.jpeg  \n",
            "  inflating: dataset/train/Recycling/aluminumcans1.png  \n",
            "  inflating: dataset/train/Recycling/aluminumcans10.jpeg  \n",
            "  inflating: dataset/train/Recycling/aluminumcans2.jpeg  \n",
            " extracting: dataset/train/Recycling/aluminumcans3.png  \n",
            "  inflating: dataset/train/Recycling/aluminumcans4.jpeg  \n",
            "  inflating: dataset/train/Recycling/aluminumcans5.png  \n",
            "  inflating: dataset/train/Recycling/aluminumcans6.jpeg  \n",
            "  inflating: dataset/train/Recycling/aluminumcans7.jpeg  \n",
            "  inflating: dataset/train/Recycling/aluminumcans8.jpeg  \n",
            "  inflating: dataset/train/Recycling/aluminumfoil0.jpeg  \n",
            "  inflating: dataset/train/Recycling/aluminumfoil1.jpeg  \n",
            "  inflating: dataset/train/Recycling/aluminumfoil2.jpeg  \n",
            "  inflating: dataset/train/Recycling/aluminumfoil4.jpeg  \n",
            "  inflating: dataset/train/Recycling/aluminumfoil5.jpeg  \n",
            "  inflating: dataset/train/Recycling/aluminumfoil6.jpeg  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "base_dir = 'dataset/train'"
      ],
      "metadata": {
        "id": "U7iHb91-oTuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "IMAGE_SIZE = 224\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "datagen = tf.keras.preprocessing.image.ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    validation_split=0.2\n",
        ")\n",
        "\n",
        "train_generator = datagen.flow_from_directory(\n",
        "    base_dir,\n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size = BATCH_SIZE,\n",
        "    subset='training'\n",
        ")\n",
        "val_generator = datagen.flow_from_directory(  #validation generator\n",
        "    base_dir, \n",
        "    target_size=(IMAGE_SIZE, IMAGE_SIZE),\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='validation'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgRbOFBZoah7",
        "outputId": "076ea9e4-9a9c-4396-e546-bf5420507d2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 56 images belonging to 2 classes.\n",
            "Found 13 images belonging to 2 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_generator.class_indices)\n",
        "labels = '\\n'.join(sorted(train_generator.class_indices.keys()))\n",
        "with open('labels.txt', 'w') as f:\n",
        "    f.write(labels)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnFgtz4vommf",
        "outputId": "dee9fc85-ee2d-4be2-8c9f-31b55a93ee89"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'Compost': 0, 'Recycling': 1}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "IMG_SHAPE = (IMAGE_SIZE, IMAGE_SIZE, 3) \n",
        "base_model = tf.keras.applications.MobileNetV2(\n",
        "    input_shape=IMG_SHAPE,\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")"
      ],
      "metadata": {
        "id": "C1ulPfgEop5c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "base_model.trainable=False\n",
        "model = tf.keras.Sequential([\n",
        "  base_model,\n",
        "  tf.keras.layers.Conv2D(32,3, activation = 'relu'),\n",
        "  tf.keras.layers.Dropout(0.2),\n",
        "  tf.keras.layers.GlobalAveragePooling2D(),\n",
        "  tf.keras.layers.Dense(2, #no.of classes\n",
        "                        activation='softmax')\n",
        "])"
      ],
      "metadata": {
        "id": "MZeBxAvWor0V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(),\n",
        "    loss='categorical_crossentropy', \n",
        "    metrics=['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "rFyRjOWCou-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "history = model.fit(\n",
        "    train_generator, \n",
        "    epochs = epochs, \n",
        "    validation_data=val_generator\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfuRbCu6ovlU",
        "outputId": "725d5d14-81dc-448a-988a-c720060b4469"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10\n",
            "1/1 [==============================] - 6s 6s/step - loss: 0.9432 - accuracy: 0.4286 - val_loss: 3.0204 - val_accuracy: 0.8462\n",
            "Epoch 2/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 3.9152 - accuracy: 0.8036 - val_loss: 2.5866 - val_accuracy: 0.8462\n",
            "Epoch 3/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 2.6848 - accuracy: 0.8036 - val_loss: 1.6805 - val_accuracy: 0.8462\n",
            "Epoch 4/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 1.1505 - accuracy: 0.8036 - val_loss: 0.7799 - val_accuracy: 0.8462\n",
            "Epoch 5/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.2612 - accuracy: 0.8393 - val_loss: 0.2465 - val_accuracy: 0.9231\n",
            "Epoch 6/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1152 - accuracy: 0.8750 - val_loss: 0.0967 - val_accuracy: 0.9231\n",
            "Epoch 7/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1028 - accuracy: 0.9464 - val_loss: 0.0523 - val_accuracy: 1.0000\n",
            "Epoch 8/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.0981 - accuracy: 0.9643 - val_loss: 0.0426 - val_accuracy: 1.0000\n",
            "Epoch 9/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1000 - accuracy: 0.9821 - val_loss: 0.0597 - val_accuracy: 1.0000\n",
            "Epoch 10/10\n",
            "1/1 [==============================] - 2s 2s/step - loss: 0.1063 - accuracy: 1.0000 - val_loss: 0.0952 - val_accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "saved_model_dir = ''\n",
        "tf.saved_model.save(model, saved_model_dir)\n",
        "\n",
        "converter = tf.lite.TFLiteConverter.from_saved_model(saved_model_dir) \n",
        "tflite_model = converter.convert()\n",
        "\n",
        "with open('model.tflite', 'wb') as f:\n",
        "  f.write(tflite_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aenpHzg-p7JQ",
        "outputId": "c1ee32be-5db8-4d7b-d673-4e34af0bea8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Function `_wrapped_model` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: assets\n",
            "WARNING:absl:Function `signature_wrapper` contains input name(s) mobilenetv2_1.00_224_input with unsupported characters which will be renamed to mobilenetv2_1_00_224_input in the SavedModel.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9fn1w_hi/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: /tmp/tmp9fn1w_hi/assets\n",
            "WARNING:absl:Buffer deduplication procedure will be skipped when flatbuffer library is not properly loaded\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "files.download('model.tflite')\n",
        "files.download('labels.txt')"
      ],
      "metadata": {
        "id": "xNJnSro8qQ8S",
        "outputId": "54528425-25ef-4d23-f915-7387a38bf7e1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_af39bd7d-f672-4fde-af66-dcf426e5a8dc\", \"model.tflite\", 10344596)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_33a36d35-e864-49b7-898a-be60f9245006\", \"labels.txt\", 17)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {}
        }
      ]
    }
  ]
}